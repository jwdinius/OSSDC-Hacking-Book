{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rpg_public_dronet Jupyter Notebook\n",
    "\n",
    "## Introduction and Relevant Info\n",
    "\n",
    "This notebook is a Jupyter conversion of this [repo](https://github.com/uzh-rpg/rpg_public_dronet).  You will need to clone the repo locally to your machine and copy this notebook into the `rpg_public_dronet` directory.\n",
    "\n",
    "I go through the process of getting the needed data, preprocessing it, and training the model using keras and Tensorflow.\n",
    "\n",
    "Before executing the code in this notebook, please note the following:\n",
    "\n",
    "* This notebook was built using [Miniconda](https://conda.io/miniconda.html)\n",
    "* The specific environment used can be built by using the `environment_gpu.yml` file included with the notebook.  For information on how to setup conda environments, see [this](https://conda.io/docs/user-guide/tasks/manage-environments.html).  You will need to choose the correct Tensorflow wheel for your operating system and gpu configuration; if you have a gpu, choose the `tensorflow_gpu` wheel, otherwise choose the cpu `tensorflow` wheel.\n",
    "\n",
    "## Getting the Raw Data\n",
    "\n",
    "* Download [the torrent files](https://github.com/udacity/self-driving-car/tree/master/datasets/CH2)\n",
    "* Process/download using [Deluge](http://deluge-torrent.org/) or other\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "Data downloaded above are ROS bagfiles and need to be processed to get png images and steering info that the CNN requires.  This section goes through the conversion process.\n",
    "\n",
    "### Bagfile Extraction\n",
    "\n",
    "Python modules to import before beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the file structure in the repo, execute the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# USER CHANGE THESE TO FIT YOUR DATA\n",
    "basedic = {'1':'/home/joe/ossdc/data/Ch2_002','2':'/home/joe/ossdc/data/HMB_3'}\n",
    "tgtdir = '/home/joe/ossdc/rpg_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMB_3\n",
      "cp -f /home/joe/ossdc/data/HMB_3/HMB_3.bag /home/joe/ossdc/rpg_data/HMB_3/HMB_3.bag\n",
      "HMB_1\n",
      "cp -f /home/joe/ossdc/data/Ch2_002/HMB_1.bag /home/joe/ossdc/rpg_data/HMB_1/HMB_1.bag\n",
      "HMB_4\n",
      "cp -f /home/joe/ossdc/data/Ch2_002/HMB_4.bag /home/joe/ossdc/rpg_data/HMB_4/HMB_4.bag\n",
      "HMB_5\n",
      "cp -f /home/joe/ossdc/data/Ch2_002/HMB_5.bag /home/joe/ossdc/rpg_data/HMB_5/HMB_5.bag\n",
      "HMB_2\n",
      "cp -f /home/joe/ossdc/data/Ch2_002/HMB_2.bag /home/joe/ossdc/rpg_data/HMB_2/HMB_2.bag\n",
      "HMB_6\n",
      "cp -f /home/joe/ossdc/data/Ch2_002/HMB_6.bag /home/joe/ossdc/rpg_data/HMB_6/HMB_6.bag\n"
     ]
    }
   ],
   "source": [
    "# Read bags\n",
    "for d in basedic.keys():\n",
    "    bags = [os.path.basename(x) for x in glob.glob(basedic[d] + \"/*.bag\")]\n",
    "    for bag in bags:\n",
    "        bagdir = re.sub(r'\\.bag$', '', bag)\n",
    "        print(bagdir)\n",
    "        bashCommand = 'mkdir ' + tgtdir + '/' + bagdir\n",
    "        process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "        bashCommand = 'cp -f ' + basedic[d] + '/' + bag + ' ' + tgtdir + '/' + bagdir + '/' + bag\n",
    "        print(bashCommand)\n",
    "        process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "        #output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the bags have been moved to a temporary directory for file extraction.  To extract the images, clone the following [repo](https://github.com/rwightman/udacity-driving-reader).\n",
    "\n",
    "To use the shell scripts in the repo, you will need to download [docker-ce](https://docs.docker.com/install/linux/docker-ce/ubuntu/).  Follow the instructions included for bagfile extraction.  For your reference, the following shell commands should work (from the top-level of the repo):\n",
    "\n",
    "```bash\n",
    "./build.sh #builds the docker container\n",
    "./run-bagdump.sh -i {root dir with folders containing bagfiles} -o {desired output dir} #processes the bagfiles\n",
    "\n",
    "```\n",
    "\n",
    "### Steps Outlined in rpg_public_dronet README.md\n",
    "\n",
    "Two steps are described, which are:\n",
    "\n",
    "* Change folder name\n",
    "* Timestamp matching\n",
    "\n",
    "#### Change folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = '/home/joe/ossdc/rpg_public_dronet/data' #change to your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMB_5\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_5/center /home/joe/ossdc/rpg_public_dronet/data/HMB_5/images\n",
      "HMB_3\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_3/center /home/joe/ossdc/rpg_public_dronet/data/HMB_3/images\n",
      "HMB_6\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_6/center /home/joe/ossdc/rpg_public_dronet/data/HMB_6/images\n",
      "HMB_4\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_4/center /home/joe/ossdc/rpg_public_dronet/data/HMB_4/images\n",
      "HMB_1\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_1/center /home/joe/ossdc/rpg_public_dronet/data/HMB_1/images\n",
      "HMB_2\n",
      "ln -sf /home/joe/ossdc/rpg_public_dronet/data/HMB_2/center /home/joe/ossdc/rpg_public_dronet/data/HMB_2/images\n"
     ]
    }
   ],
   "source": [
    "for fn in os.listdir(basedir):\n",
    "  if not os.path.isdir(os.path.join(basedir, fn)):\n",
    "    continue # Not a directory\n",
    "  else:\n",
    "    print(fn)\n",
    "    center = basedir + '/' + fn + '/center'\n",
    "    images = basedir + '/' + fn + '/images'\n",
    "    bashCommand = 'ln -sf ' + center + ' ' + images\n",
    "    print(bashCommand)\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Stamp Matching\n",
    "The cells below implement [time_stamp_matching.py](https://github.com/uzh-rpg/rpg_public_dronet/blob/master/data_preprocessing/time_stamp_matching.py) from the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractInfoFromFile(file_name):\n",
    "    steer_stamps = []\n",
    "    # Read file and extract time stamp\n",
    "    try:\n",
    "       steer_stamps = np.loadtxt(file_name, usecols=1, delimiter=',', skiprows=1, dtype=int)\n",
    "    except:\n",
    "        print(file_name)\n",
    "    return steer_stamps\n",
    "\n",
    "\n",
    "def getMatching(array1, array2):\n",
    "    match_stamps = []\n",
    "    match_idx = []\n",
    "    for i in array1:\n",
    "        dist = abs(i - array2)\n",
    "        idx = np.where(dist == 0)[0]\n",
    "        match_stamps.append(array2[idx])\n",
    "        match_idx.append(idx)\n",
    "    return match_stamps, match_idx\n",
    "\n",
    "\n",
    "def getSyncSteering(fname, idx):\n",
    "    mat = []\n",
    "    try:\n",
    "        mat = np.loadtxt(fname, usecols=(6,7,8,9,10,11), skiprows=1, delimiter=',')\n",
    "        mat = mat[idx,:]\n",
    "    except:\n",
    "        print(fname)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the data extracted from the Udacity dataset\n",
    "folder = \"./data\" #\"training\"  or \"testing\"\n",
    "assert folder, \"You should provide the dataset folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/HMB_5\n",
      "(4235, 1)\n",
      "./data/HMB_3\n",
      "(5279, 1)\n",
      "./data/HMB_6\n",
      "(7402, 1)\n",
      "./data/HMB_4\n",
      "(1974, 1)\n",
      "./data/HMB_1\n",
      "(4401, 1)\n",
      "./data/HMB_2\n",
      "(15796, 1)\n"
     ]
    }
   ],
   "source": [
    "experiments = glob.glob(folder + \"/*\")\n",
    "# For every bag...\n",
    "for exp in experiments:\n",
    "    print(exp)\n",
    "    # Read images\n",
    "    images = [os.path.basename(x) for x in glob.glob(exp + \"/images/*.png\")]\n",
    "    im_stamps = []\n",
    "    for im in images:\n",
    "        stamp = int(re.sub(r'\\.png$', '', im))\n",
    "        #print(stamp)\n",
    "        im_stamps.append(stamp)\n",
    "    im_stamps = np.array(sorted(im_stamps))\n",
    "\n",
    "    # Extract time stamps from steerings\n",
    "    file_name = exp + \"/interpolated.csv\"\n",
    "    steer_stamps = extractInfoFromFile(file_name)\n",
    "\n",
    "    # Time-stamp matching between images and steerings\n",
    "    match_stamp, match_idx = getMatching(im_stamps, steer_stamps)\n",
    "    match_idx = np.array(match_idx)\n",
    "    print(match_idx.shape)\n",
    "    try:\n",
    "        match_idx = match_idx[:,0]\n",
    "        # Get matched commands\n",
    "        original_fname = exp + \"/interpolated.csv\"\n",
    "        sync_steer = getSyncSteering(original_fname, match_idx)\n",
    "        new_fname = exp + \"/sync_steering.txt\"\n",
    "        np.savetxt(new_fname, sync_steer, delimiter=',',\n",
    "                   header=\"angle,torque,speed,lat,long,alt\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training, validation, and testing folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p ./data/training\n",
      "mkdir -p ./data/validation\n",
      "mkdir -p ./data/testing\n",
      "mkdir -p ./data/training/HMB_5/images\n",
      "cp -f ./data/HMB_5/center/*.png ./data/training/HMB_5/images\n",
      "cp -f ./data/HMB_5/sync_steering.txt ./data/training/HMB_5/\n",
      "None\n",
      "mkdir -p ./data/testing/HMB_3/images\n",
      "cp -f ./data/HMB_3/center/*.png ./data/testing/HMB_3/images/\n",
      "cp -f ./data/HMB_3/sync_steering.txt ./data/testing/HMB_3/\n",
      "None\n",
      "mkdir -p ./data/training/HMB_6/images\n",
      "cp -f ./data/HMB_6/center/*.png ./data/training/HMB_6/images\n",
      "cp -f ./data/HMB_6/sync_steering.txt ./data/training/HMB_6/\n",
      "None\n",
      "mkdir -p ./data/validation/HMB_4/images\n",
      "cp -f ./data/HMB_4/center/*.png ./data/validation/HMB_4/images\n",
      "cp -f ./data/HMB_4/sync_steering.txt ./data/validation/HMB_4/\n",
      "None\n",
      "mkdir -p ./data/training/HMB_1/images\n",
      "cp -f ./data/HMB_1/center/*.png ./data/training/HMB_1/images\n",
      "cp -f ./data/HMB_1/sync_steering.txt ./data/training/HMB_1/\n",
      "None\n",
      "mkdir -p ./data/training/HMB_2/images\n",
      "cp -f ./data/HMB_2/center/*.png ./data/training/HMB_2/images\n",
      "cp -f ./data/HMB_2/sync_steering.txt ./data/training/HMB_2/\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "basedir = './data'\n",
    "\n",
    "bashCommand = 'mkdir -p ' + basedir + '/training'\n",
    "print(bashCommand)\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "\n",
    "bashCommand = 'mkdir -p ' + basedir + '/validation'\n",
    "print(bashCommand)\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "\n",
    "bashCommand = 'mkdir -p ' + basedir + '/testing'\n",
    "print(bashCommand)\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "\n",
    "for exp in experiments:\n",
    "    expname = re.sub(r'./data/', '', exp)\n",
    "    #print(expname)\n",
    "    if expname == 'HMB_1' or expname == 'HMB_2' or expname == 'HMB_5' or expname == 'HMB_6':\n",
    "        bashCommand0 = 'mkdir -p ' + basedir + '/training/' + expname + '/images'\n",
    "        bashCommand1 = 'cp -f ' + exp + '/center/*.png ' + basedir + '/training/' + expname + '/images'\n",
    "        bashCommand2 = 'cp -f ' + exp + '/sync_steering.txt ' + basedir + '/training/' + expname + '/'\n",
    "    elif exp == './data/HMB_4':\n",
    "        bashCommand0 = 'mkdir -p ' + basedir + '/validation/' + expname + '/images'\n",
    "        bashCommand1 = 'cp -f ' + exp + '/center/*.png ' + basedir + '/validation/' + expname + '/images'\n",
    "        bashCommand2 = 'cp -f ' + exp + '/sync_steering.txt ' + basedir + '/validation/' + expname + '/'\n",
    "    else:\n",
    "        bashCommand0 = 'mkdir -p ' + basedir + '/testing/' + expname + '/images'\n",
    "        bashCommand1 = 'cp -f ' + exp + '/center/*.png ' + basedir + '/testing/' + expname + '/images/'\n",
    "        bashCommand2 = 'cp -f ' + exp + '/sync_steering.txt ' + basedir + '/testing/' + expname + '/'\n",
    "    print(bashCommand0)\n",
    "    print(bashCommand1)\n",
    "    print(bashCommand2)\n",
    "    process = subprocess.Popen(bashCommand0.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    process = subprocess.Popen(bashCommand1.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(error)\n",
    "    process = subprocess.Popen(bashCommand2.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Cleanup\n",
    "\n",
    "After verification of proper formatting, remove the `HMB_*` directories from the top-level data directory:\n",
    "\n",
    "```bash\n",
    "rm -rf {path_to_data}/HMB_*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DroNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gpu support is available\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output (to terminal running this notebook) was:\n",
    "\n",
    "```bash\n",
    "\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
    "name: GeForce GTX 1080 Ti\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
    "pciBusID 0000:01:00.0\n",
    "Total memory: 10.91GiB\n",
    "Free memory: 10.14GiB\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)\n",
    "Device mapping:\n",
    "/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\n",
    "I tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\n",
    "/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\n",
    "\n",
    "```\n",
    "\n",
    "Tensorflow found a GTX1080Ti and will use it.\n",
    "\n",
    "Now, you should be ready to train the CNN.  _Note: I had issues with pydot and vizgraph when trying to export a png image of the CNN.  After commenting out the lines of cnn.py responsible for exporting the architecture.png file, I was able to train the network without further problems._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/joe/miniconda3/envs/rpg_public_dronet/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61696 images belonging to 131 experiments.\n",
      "Found 2508 images belonging to 3 experiments.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200, 200, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 100, 100, 32)  832                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 49, 49, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 49, 49, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 49, 49, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 32)    9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 25, 25, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 25, 25, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 25, 25, 32)    1056                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 25, 25, 32)    9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 25, 25, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 25, 25, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 25, 25, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 13, 13, 64)    18496                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 13, 13, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 13, 13, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 13, 13, 64)    2112                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 13, 13, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 13, 13, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 13, 13, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 13, 13, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 7, 7, 128)     73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 7, 7, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 7, 7, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 7, 7, 128)     8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 7, 7, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 7, 7, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 6272)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 6272)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 6272)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             6273                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             6273                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 1)             0                                            \n",
      "====================================================================================================\n",
      "Total params: 321,634\n",
      "Trainable params: 320,930\n",
      "Non-trainable params: 704\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "\u001b[32;1mLogging data to ./model/test_1/log.txt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/miniconda3/envs/rpg_public_dronet/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/joe/miniconda3/envs/rpg_public_dronet/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "Epoch 1/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1077 - dense_1_loss: 0.0461 - activation_8_loss: 0.3409-------------------------------------\n",
      "|      train_loss |           0.108 |\n",
      "|        val_loss |          0.0912 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1334s - loss: 0.1077 - dense_1_loss: 0.0461 - activation_8_loss: 0.3408 - val_loss: 0.0912 - val_dense_1_loss: 0.0452 - val_activation_8_loss: 0.1524\n",
      "1.0\n",
      "0.0\n",
      "Epoch 2/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0622 - dense_1_loss: 0.0369 - activation_8_loss: 0.3353-------------------------------------\n",
      "|      train_loss |          0.0622 |\n",
      "|        val_loss |          0.0557 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1223s - loss: 0.0622 - dense_1_loss: 0.0369 - activation_8_loss: 0.3353 - val_loss: 0.0557 - val_dense_1_loss: 0.0476 - val_activation_8_loss: 0.1474\n",
      "1.0\n",
      "0.0\n",
      "Epoch 3/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0405 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0405 |\n",
      "|        val_loss |          0.0475 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1226s - loss: 0.0405 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0475 - val_dense_1_loss: 0.0474 - val_activation_8_loss: 0.1481\n",
      "1.0\n",
      "0.0\n",
      "Epoch 4/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0395 - dense_1_loss: 0.0386 - activation_8_loss: 0.3356-------------------------------------\n",
      "|      train_loss |          0.0395 |\n",
      "|        val_loss |          0.0477 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1228s - loss: 0.0395 - dense_1_loss: 0.0386 - activation_8_loss: 0.3355 - val_loss: 0.0477 - val_dense_1_loss: 0.0476 - val_activation_8_loss: 0.1461\n",
      "1.0\n",
      "0.0\n",
      "Epoch 5/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0468 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1226s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0468 - val_dense_1_loss: 0.0468 - val_activation_8_loss: 0.1474\n",
      "1.0\n",
      "0.0\n",
      "Epoch 6/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0475 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1226s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0475 - val_dense_1_loss: 0.0475 - val_activation_8_loss: 0.1502\n",
      "1.0\n",
      "0.0\n",
      "Epoch 7/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0472 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1228s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0472 - val_dense_1_loss: 0.0472 - val_activation_8_loss: 0.1480\n",
      "1.0\n",
      "0.0\n",
      "Epoch 8/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0479 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1222s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0479 - val_dense_1_loss: 0.0479 - val_activation_8_loss: 0.1445\n",
      "1.0\n",
      "0.0\n",
      "Epoch 9/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0467 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1215s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0467 - val_dense_1_loss: 0.0467 - val_activation_8_loss: 0.1510\n",
      "1.0\n",
      "0.0\n",
      "Epoch 10/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |           0.048 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1220s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0480 - val_dense_1_loss: 0.0480 - val_activation_8_loss: 0.1463\n",
      "1.0\n",
      "0.0\n",
      "Epoch 11/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355-------------------------------------\n",
      "|      train_loss |          0.0385 |\n",
      "|        val_loss |          0.0474 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1184s - loss: 0.0385 - dense_1_loss: 0.0385 - activation_8_loss: 0.3355 - val_loss: 0.0474 - val_dense_1_loss: 0.0474 - val_activation_8_loss: 0.1461\n",
      "1.0\n",
      "0.095162585\n",
      "Epoch 12/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0598 - dense_1_loss: 0.0385 - activation_8_loss: 0.2236-------------------------------------\n",
      "|      train_loss |          0.0598 |\n",
      "|        val_loss |          0.0532 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 1016s - loss: 0.0598 - dense_1_loss: 0.0385 - activation_8_loss: 0.2236 - val_loss: 0.0532 - val_dense_1_loss: 0.0470 - val_activation_8_loss: 0.0642\n",
      "1.0\n",
      "0.18126924\n",
      "Epoch 13/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0777 - dense_1_loss: 0.0385 - activation_8_loss: 0.2160-------------------------------------\n",
      "|      train_loss |          0.0776 |\n",
      "|        val_loss |          0.0593 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 762s - loss: 0.0776 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0593 - val_dense_1_loss: 0.0484 - val_activation_8_loss: 0.0601\n",
      "1.0\n",
      "0.25918177\n",
      "Epoch 14/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.0945 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |          0.0945 |\n",
      "|        val_loss |          0.0636 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 671s - loss: 0.0945 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0636 - val_dense_1_loss: 0.0468 - val_activation_8_loss: 0.0646\n",
      "1.0\n",
      "0.32967997\n",
      "Epoch 15/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1097 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |            0.11 |\n",
      "|        val_loss |          0.0683 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 672s - loss: 0.1097 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0683 - val_dense_1_loss: 0.0475 - val_activation_8_loss: 0.0632\n",
      "1.0\n",
      "0.39346933\n",
      "Epoch 16/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1235 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.123 |\n",
      "|        val_loss |          0.0724 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 670s - loss: 0.1235 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0724 - val_dense_1_loss: 0.0476 - val_activation_8_loss: 0.0631\n",
      "1.0\n",
      "0.45118836\n",
      "Epoch 17/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1359 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.136 |\n",
      "|        val_loss |          0.0737 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 [==============================] - 675s - loss: 0.1359 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0737 - val_dense_1_loss: 0.0470 - val_activation_8_loss: 0.0592\n",
      "1.0\n",
      "0.5034147\n",
      "Epoch 18/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1472 - dense_1_loss: 0.0385 - activation_8_loss: 0.2160-------------------------------------\n",
      "|      train_loss |           0.147 |\n",
      "|        val_loss |          0.0808 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.1472 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0808 - val_dense_1_loss: 0.0475 - val_activation_8_loss: 0.0663\n",
      "1.0\n",
      "0.55067104\n",
      "Epoch 19/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1574 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.157 |\n",
      "|        val_loss |          0.0818 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.1574 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0818 - val_dense_1_loss: 0.0475 - val_activation_8_loss: 0.0622\n",
      "1.0\n",
      "0.59343034\n",
      "Epoch 20/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1666 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.167 |\n",
      "|        val_loss |          0.0849 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 648s - loss: 0.1666 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0849 - val_dense_1_loss: 0.0480 - val_activation_8_loss: 0.0622\n",
      "1.0\n",
      "0.63212055\n",
      "Epoch 21/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1750 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.175 |\n",
      "|        val_loss |          0.0872 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.1750 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0872 - val_dense_1_loss: 0.0485 - val_activation_8_loss: 0.0612\n",
      "1.0\n",
      "0.6671289\n",
      "Epoch 22/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1826 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.183 |\n",
      "|        val_loss |          0.0919 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.1826 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0919 - val_dense_1_loss: 0.0471 - val_activation_8_loss: 0.0671\n",
      "1.0\n",
      "0.6988058\n",
      "Epoch 23/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1894 - dense_1_loss: 0.0385 - activation_8_loss: 0.2160-------------------------------------\n",
      "|      train_loss |           0.189 |\n",
      "|        val_loss |            0.09 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.1894 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0900 - val_dense_1_loss: 0.0469 - val_activation_8_loss: 0.0617\n",
      "1.0\n",
      "0.7274682\n",
      "Epoch 24/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.1956 - dense_1_loss: 0.0385 - activation_8_loss: 0.2160-------------------------------------\n",
      "|      train_loss |           0.196 |\n",
      "|        val_loss |          0.0947 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.1956 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0947 - val_dense_1_loss: 0.0499 - val_activation_8_loss: 0.0617\n",
      "1.0\n",
      "0.753403\n",
      "Epoch 25/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2012 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.201 |\n",
      "|        val_loss |          0.0928 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_24.h5\n",
      "3856/3856 [==============================] - 656s - loss: 0.2012 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0928 - val_dense_1_loss: 0.0464 - val_activation_8_loss: 0.0616\n",
      "1.0\n",
      "0.77686983\n",
      "Epoch 26/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2062 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.206 |\n",
      "|        val_loss |          0.0954 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 657s - loss: 0.2062 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0954 - val_dense_1_loss: 0.0467 - val_activation_8_loss: 0.0627\n",
      "1.0\n",
      "0.7981035\n",
      "Epoch 27/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2108 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.211 |\n",
      "|        val_loss |          0.0986 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.2108 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0986 - val_dense_1_loss: 0.0482 - val_activation_8_loss: 0.0631\n",
      "1.0\n",
      "0.8173165\n",
      "Epoch 28/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2150 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.215 |\n",
      "|        val_loss |           0.101 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.2150 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.1005 - val_dense_1_loss: 0.0481 - val_activation_8_loss: 0.0642\n",
      "1.0\n",
      "0.8347011\n",
      "Epoch 29/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2187 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.219 |\n",
      "|        val_loss |           0.102 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.2187 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.1016 - val_dense_1_loss: 0.0481 - val_activation_8_loss: 0.0641\n",
      "1.0\n",
      "0.8504314\n",
      "Epoch 30/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2221 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.222 |\n",
      "|        val_loss |           0.102 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.2221 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.1022 - val_dense_1_loss: 0.0472 - val_activation_8_loss: 0.0647\n",
      "1.0\n",
      "0.86466473\n",
      "Epoch 31/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2252 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |           0.225 |\n",
      "|        val_loss |          0.0986 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.2252 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.0986 - val_dense_1_loss: 0.0469 - val_activation_8_loss: 0.0597\n",
      "1.0\n",
      "0.87754357\n",
      "Epoch 32/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2280 - dense_1_loss: 0.0385 - activation_8_loss: 0.2160-------------------------------------\n",
      "|      train_loss |           0.228 |\n",
      "|        val_loss |           0.103 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.2280 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.1028 - val_dense_1_loss: 0.0471 - val_activation_8_loss: 0.0634\n",
      "1.0\n",
      "0.8891968\n",
      "Epoch 33/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2305 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159-------------------------------------\n",
      "|      train_loss |            0.23 |\n",
      "|        val_loss |           0.103 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.2305 - dense_1_loss: 0.0385 - activation_8_loss: 0.2159 - val_loss: 0.1033 - val_dense_1_loss: 0.0467 - val_activation_8_loss: 0.0636\n",
      "1.0\n",
      "0.8997412\n",
      "Epoch 34/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2457 - dense_1_loss: 0.0385 - activation_8_loss: 0.2303-------------------------------------\n",
      "|      train_loss |           0.246 |\n",
      "|        val_loss |           0.109 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 646s - loss: 0.2457 - dense_1_loss: 0.0385 - activation_8_loss: 0.2303 - val_loss: 0.1086 - val_dense_1_loss: 0.0489 - val_activation_8_loss: 0.0664\n",
      "1.0\n",
      "0.909282\n",
      "Epoch 35/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2505 - dense_1_loss: 0.0411 - activation_8_loss: 0.2304-------------------------------------\n",
      "|      train_loss |            0.25 |\n",
      "|        val_loss |           0.111 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.2505 - dense_1_loss: 0.0411 - activation_8_loss: 0.2303 - val_loss: 0.1111 - val_dense_1_loss: 0.0498 - val_activation_8_loss: 0.0675\n",
      "1.0\n",
      "0.917915\n",
      "Epoch 36/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2525 - dense_1_loss: 0.0411 - activation_8_loss: 0.2304-------------------------------------\n",
      "|      train_loss |           0.252 |\n",
      "|        val_loss |           0.111 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.2525 - dense_1_loss: 0.0411 - activation_8_loss: 0.2303 - val_loss: 0.1108 - val_dense_1_loss: 0.0499 - val_activation_8_loss: 0.0663\n",
      "1.0\n",
      "0.9257264\n",
      "Epoch 37/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2695 - dense_1_loss: 0.0411 - activation_8_loss: 0.2467-------------------------------------\n",
      "|      train_loss |            0.27 |\n",
      "|        val_loss |           0.119 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.2695 - dense_1_loss: 0.0411 - activation_8_loss: 0.2468 - val_loss: 0.1192 - val_dense_1_loss: 0.0519 - val_activation_8_loss: 0.0727\n",
      "1.0\n",
      "0.9327945\n",
      "Epoch 38/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2712 - dense_1_loss: 0.0411 - activation_8_loss: 0.2468-------------------------------------\n",
      "|      train_loss |           0.271 |\n",
      "|        val_loss |           0.114 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.2712 - dense_1_loss: 0.0411 - activation_8_loss: 0.2467 - val_loss: 0.1143 - val_dense_1_loss: 0.0502 - val_activation_8_loss: 0.0687\n",
      "1.0\n",
      "0.9391899\n",
      "Epoch 39/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2729 - dense_1_loss: 0.0411 - activation_8_loss: 0.2468-------------------------------------\n",
      "|      train_loss |           0.273 |\n",
      "|        val_loss |            0.12 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.2728 - dense_1_loss: 0.0411 - activation_8_loss: 0.2468 - val_loss: 0.1204 - val_dense_1_loss: 0.0513 - val_activation_8_loss: 0.0735\n",
      "1.0\n",
      "0.9449768\n",
      "Epoch 40/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2921 - dense_1_loss: 0.0410 - activation_8_loss: 0.2657-------------------------------------\n",
      "|      train_loss |           0.292 |\n",
      "|        val_loss |           0.121 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.2922 - dense_1_loss: 0.0411 - activation_8_loss: 0.2657 - val_loss: 0.1212 - val_dense_1_loss: 0.0500 - val_activation_8_loss: 0.0753\n",
      "1.0\n",
      "0.95021296\n",
      "Epoch 41/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2965 - dense_1_loss: 0.0440 - activation_8_loss: 0.2658-------------------------------------\n",
      "|      train_loss |           0.297 |\n",
      "|        val_loss |           0.128 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.2965 - dense_1_loss: 0.0440 - activation_8_loss: 0.2657 - val_loss: 0.1276 - val_dense_1_loss: 0.0547 - val_activation_8_loss: 0.0767\n",
      "1.0\n",
      "0.9549508\n",
      "Epoch 42/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2978 - dense_1_loss: 0.0440 - activation_8_loss: 0.2658-------------------------------------\n",
      "|      train_loss |           0.298 |\n",
      "|        val_loss |            0.13 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.2978 - dense_1_loss: 0.0440 - activation_8_loss: 0.2657 - val_loss: 0.1304 - val_dense_1_loss: 0.0550 - val_activation_8_loss: 0.0790\n",
      "1.0\n",
      "0.9592378\n",
      "Epoch 43/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.2988 - dense_1_loss: 0.0440 - activation_8_loss: 0.2657-------------------------------------\n",
      "|      train_loss |           0.299 |\n",
      "|        val_loss |           0.128 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.2989 - dense_1_loss: 0.0440 - activation_8_loss: 0.2657 - val_loss: 0.1280 - val_dense_1_loss: 0.0544 - val_activation_8_loss: 0.0768\n",
      "1.0\n",
      "0.9631168\n",
      "Epoch 44/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3212 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878-------------------------------------\n",
      "|      train_loss |           0.321 |\n",
      "|        val_loss |           0.133 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.3211 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878 - val_loss: 0.1329 - val_dense_1_loss: 0.0549 - val_activation_8_loss: 0.0810\n",
      "1.0\n",
      "0.9666267\n",
      "Epoch 45/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3222 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878-------------------------------------\n",
      "|      train_loss |           0.322 |\n",
      "|        val_loss |           0.134 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.3221 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878 - val_loss: 0.1341 - val_dense_1_loss: 0.0539 - val_activation_8_loss: 0.0830\n",
      "1.0\n",
      "0.9698026\n",
      "Epoch 46/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3231 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878-------------------------------------\n",
      "|      train_loss |           0.323 |\n",
      "|        val_loss |           0.139 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.3231 - dense_1_loss: 0.0440 - activation_8_loss: 0.2878 - val_loss: 0.1394 - val_dense_1_loss: 0.0550 - val_activation_8_loss: 0.0870\n",
      "1.0\n",
      "0.9726763\n",
      "Epoch 47/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3237 - dense_1_loss: 0.0440 - activation_8_loss: 0.2876-------------------------------------\n",
      "|      train_loss |           0.324 |\n",
      "|        val_loss |           0.135 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.3239 - dense_1_loss: 0.0440 - activation_8_loss: 0.2877 - val_loss: 0.1346 - val_dense_1_loss: 0.0518 - val_activation_8_loss: 0.0851\n",
      "1.0\n",
      "0.97527647\n",
      "Epoch 48/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3496 - dense_1_loss: 0.0440 - activation_8_loss: 0.3134-------------------------------------\n",
      "|      train_loss |            0.35 |\n",
      "|        val_loss |           0.146 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.3497 - dense_1_loss: 0.0440 - activation_8_loss: 0.3135 - val_loss: 0.1461 - val_dense_1_loss: 0.0553 - val_activation_8_loss: 0.0931\n",
      "1.0\n",
      "0.97762924\n",
      "Epoch 49/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3538 - dense_1_loss: 0.0473 - activation_8_loss: 0.3134-------------------------------------\n",
      "|      train_loss |           0.354 |\n",
      "|        val_loss |           0.138 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.3539 - dense_1_loss: 0.0474 - activation_8_loss: 0.3135 - val_loss: 0.1381 - val_dense_1_loss: 0.0592 - val_activation_8_loss: 0.0807\n",
      "1.0\n",
      "0.9797581\n",
      "Epoch 50/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3545 - dense_1_loss: 0.0474 - activation_8_loss: 0.3134-------------------------------------\n",
      "|      train_loss |           0.355 |\n",
      "|        val_loss |           0.159 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_49.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 [==============================] - 664s - loss: 0.3545 - dense_1_loss: 0.0474 - activation_8_loss: 0.3135 - val_loss: 0.1586 - val_dense_1_loss: 0.0581 - val_activation_8_loss: 0.1026\n",
      "1.0\n",
      "0.9816844\n",
      "Epoch 51/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3551 - dense_1_loss: 0.0474 - activation_8_loss: 0.3134-------------------------------------\n",
      "|      train_loss |           0.355 |\n",
      "|        val_loss |           0.145 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.3551 - dense_1_loss: 0.0474 - activation_8_loss: 0.3134 - val_loss: 0.1449 - val_dense_1_loss: 0.0566 - val_activation_8_loss: 0.0900\n",
      "1.0\n",
      "0.98342735\n",
      "Epoch 52/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3557 - dense_1_loss: 0.0474 - activation_8_loss: 0.3135-------------------------------------\n",
      "|      train_loss |           0.356 |\n",
      "|        val_loss |           0.147 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 650s - loss: 0.3557 - dense_1_loss: 0.0474 - activation_8_loss: 0.3135 - val_loss: 0.1466 - val_dense_1_loss: 0.0572 - val_activation_8_loss: 0.0909\n",
      "1.0\n",
      "0.9850044\n",
      "Epoch 53/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3855 - dense_1_loss: 0.0474 - activation_8_loss: 0.3433-------------------------------------\n",
      "|      train_loss |           0.385 |\n",
      "|        val_loss |           0.157 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 650s - loss: 0.3855 - dense_1_loss: 0.0474 - activation_8_loss: 0.3433 - val_loss: 0.1566 - val_dense_1_loss: 0.0595 - val_activation_8_loss: 0.0986\n",
      "1.0\n",
      "0.9864314\n",
      "Epoch 54/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3859 - dense_1_loss: 0.0474 - activation_8_loss: 0.3432-------------------------------------\n",
      "|      train_loss |           0.386 |\n",
      "|        val_loss |           0.162 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.3860 - dense_1_loss: 0.0474 - activation_8_loss: 0.3432 - val_loss: 0.1625 - val_dense_1_loss: 0.0616 - val_activation_8_loss: 0.1022\n",
      "1.0\n",
      "0.98772264\n",
      "Epoch 55/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3864 - dense_1_loss: 0.0474 - activation_8_loss: 0.3433-------------------------------------\n",
      "|      train_loss |           0.386 |\n",
      "|        val_loss |           0.154 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.3864 - dense_1_loss: 0.0474 - activation_8_loss: 0.3433 - val_loss: 0.1536 - val_dense_1_loss: 0.0563 - val_activation_8_loss: 0.0985\n",
      "1.0\n",
      "0.988891\n",
      "Epoch 56/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3870 - dense_1_loss: 0.0474 - activation_8_loss: 0.3434-------------------------------------\n",
      "|      train_loss |           0.387 |\n",
      "|        val_loss |           0.154 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.3869 - dense_1_loss: 0.0474 - activation_8_loss: 0.3434 - val_loss: 0.1540 - val_dense_1_loss: 0.0596 - val_activation_8_loss: 0.0955\n",
      "1.0\n",
      "0.98994815\n",
      "Epoch 57/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3872 - dense_1_loss: 0.0474 - activation_8_loss: 0.3432-------------------------------------\n",
      "|      train_loss |           0.387 |\n",
      "|        val_loss |           0.163 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.3872 - dense_1_loss: 0.0474 - activation_8_loss: 0.3433 - val_loss: 0.1631 - val_dense_1_loss: 0.0585 - val_activation_8_loss: 0.1057\n",
      "1.0\n",
      "0.99090475\n",
      "Epoch 58/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.3874 - dense_1_loss: 0.0474 - activation_8_loss: 0.3432-------------------------------------\n",
      "|      train_loss |           0.387 |\n",
      "|        val_loss |           0.156 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.3875 - dense_1_loss: 0.0474 - activation_8_loss: 0.3432 - val_loss: 0.1558 - val_dense_1_loss: 0.0588 - val_activation_8_loss: 0.0979\n",
      "1.0\n",
      "0.99177027\n",
      "Epoch 59/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4257 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775-------------------------------------\n",
      "|      train_loss |           0.426 |\n",
      "|        val_loss |           0.178 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.4257 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775 - val_loss: 0.1776 - val_dense_1_loss: 0.0641 - val_activation_8_loss: 0.1144\n",
      "1.0\n",
      "0.9925534\n",
      "Epoch 60/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4261 - dense_1_loss: 0.0513 - activation_8_loss: 0.3776-------------------------------------\n",
      "|      train_loss |           0.426 |\n",
      "|        val_loss |           0.177 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.4262 - dense_1_loss: 0.0513 - activation_8_loss: 0.3776 - val_loss: 0.1766 - val_dense_1_loss: 0.0640 - val_activation_8_loss: 0.1134\n",
      "1.0\n",
      "0.99326205\n",
      "Epoch 61/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4263 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775-------------------------------------\n",
      "|      train_loss |           0.426 |\n",
      "|        val_loss |           0.168 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.4263 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775 - val_loss: 0.1683 - val_dense_1_loss: 0.0631 - val_activation_8_loss: 0.1059\n",
      "1.0\n",
      "0.9939033\n",
      "Epoch 62/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4264 - dense_1_loss: 0.0513 - activation_8_loss: 0.3774-------------------------------------\n",
      "|      train_loss |           0.426 |\n",
      "|        val_loss |           0.178 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.4264 - dense_1_loss: 0.0513 - activation_8_loss: 0.3774 - val_loss: 0.1778 - val_dense_1_loss: 0.0637 - val_activation_8_loss: 0.1149\n",
      "1.0\n",
      "0.9944834\n",
      "Epoch 63/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4267 - dense_1_loss: 0.0513 - activation_8_loss: 0.3774-------------------------------------\n",
      "|      train_loss |           0.427 |\n",
      "|        val_loss |           0.184 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.4267 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775 - val_loss: 0.1837 - val_dense_1_loss: 0.0631 - val_activation_8_loss: 0.1213\n",
      "1.0\n",
      "0.9950084\n",
      "Epoch 64/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4271 - dense_1_loss: 0.0513 - activation_8_loss: 0.3776-------------------------------------\n",
      "|      train_loss |           0.427 |\n",
      "|        val_loss |           0.173 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.4272 - dense_1_loss: 0.0513 - activation_8_loss: 0.3778 - val_loss: 0.1729 - val_dense_1_loss: 0.0631 - val_activation_8_loss: 0.1104\n",
      "1.0\n",
      "0.9954834\n",
      "Epoch 65/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4275 - dense_1_loss: 0.0513 - activation_8_loss: 0.3778-------------------------------------\n",
      "|      train_loss |           0.427 |\n",
      "|        val_loss |           0.181 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 663s - loss: 0.4274 - dense_1_loss: 0.0513 - activation_8_loss: 0.3778 - val_loss: 0.1812 - val_dense_1_loss: 0.0641 - val_activation_8_loss: 0.1177\n",
      "1.0\n",
      "0.9959132\n",
      "Epoch 66/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4272 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775-------------------------------------\n",
      "|      train_loss |           0.427 |\n",
      "|        val_loss |           0.169 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 663s - loss: 0.4272 - dense_1_loss: 0.0513 - activation_8_loss: 0.3775 - val_loss: 0.1691 - val_dense_1_loss: 0.0625 - val_activation_8_loss: 0.1071\n",
      "1.0\n",
      "0.9963021\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4660 - dense_1_loss: 0.0513 - activation_8_loss: 0.4162-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |             0.2 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 648s - loss: 0.4659 - dense_1_loss: 0.0513 - activation_8_loss: 0.4162 - val_loss: 0.1998 - val_dense_1_loss: 0.0643 - val_activation_8_loss: 0.1360\n",
      "1.0\n",
      "0.99665403\n",
      "Epoch 68/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4663 - dense_1_loss: 0.0513 - activation_8_loss: 0.4163-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |           0.184 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 650s - loss: 0.4662 - dense_1_loss: 0.0513 - activation_8_loss: 0.4163 - val_loss: 0.1843 - val_dense_1_loss: 0.0622 - val_activation_8_loss: 0.1226\n",
      "1.0\n",
      "0.99697244\n",
      "Epoch 69/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4661 - dense_1_loss: 0.0514 - activation_8_loss: 0.4160-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |           0.207 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.4662 - dense_1_loss: 0.0513 - activation_8_loss: 0.4161 - val_loss: 0.2069 - val_dense_1_loss: 0.0657 - val_activation_8_loss: 0.1416\n",
      "1.0\n",
      "0.9972606\n",
      "Epoch 70/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4667 - dense_1_loss: 0.0513 - activation_8_loss: 0.4165-------------------------------------\n",
      "|      train_loss |           0.467 |\n",
      "|        val_loss |           0.191 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.4666 - dense_1_loss: 0.0513 - activation_8_loss: 0.4164 - val_loss: 0.1906 - val_dense_1_loss: 0.0623 - val_activation_8_loss: 0.1286\n",
      "1.0\n",
      "0.9975212\n",
      "Epoch 71/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4662 - dense_1_loss: 0.0513 - activation_8_loss: 0.4159-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |           0.196 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 657s - loss: 0.4662 - dense_1_loss: 0.0513 - activation_8_loss: 0.4159 - val_loss: 0.1963 - val_dense_1_loss: 0.0642 - val_activation_8_loss: 0.1324\n",
      "1.0\n",
      "0.99775714\n",
      "Epoch 72/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4665 - dense_1_loss: 0.0513 - activation_8_loss: 0.4161-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |           0.188 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.4665 - dense_1_loss: 0.0513 - activation_8_loss: 0.4161 - val_loss: 0.1875 - val_dense_1_loss: 0.0627 - val_activation_8_loss: 0.1252\n",
      "1.0\n",
      "0.9979706\n",
      "Epoch 73/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4665 - dense_1_loss: 0.0513 - activation_8_loss: 0.4160-------------------------------------\n",
      "|      train_loss |           0.466 |\n",
      "|        val_loss |           0.188 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.4665 - dense_1_loss: 0.0513 - activation_8_loss: 0.4160 - val_loss: 0.1879 - val_dense_1_loss: 0.0611 - val_activation_8_loss: 0.1271\n",
      "1.0\n",
      "0.9981637\n",
      "Epoch 74/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4715 - dense_1_loss: 0.0559 - activation_8_loss: 0.4163-------------------------------------\n",
      "|      train_loss |           0.472 |\n",
      "|        val_loss |           0.199 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.4716 - dense_1_loss: 0.0560 - activation_8_loss: 0.4164 - val_loss: 0.1991 - val_dense_1_loss: 0.0693 - val_activation_8_loss: 0.1300\n",
      "1.0\n",
      "0.99833846\n",
      "Epoch 75/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4713 - dense_1_loss: 0.0560 - activation_8_loss: 0.4160-------------------------------------\n",
      "|      train_loss |           0.471 |\n",
      "|        val_loss |           0.197 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_74.h5\n",
      "3856/3856 [==============================] - 660s - loss: 0.4714 - dense_1_loss: 0.0560 - activation_8_loss: 0.4161 - val_loss: 0.1967 - val_dense_1_loss: 0.0676 - val_activation_8_loss: 0.1293\n",
      "1.0\n",
      "0.99849653\n",
      "Epoch 76/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.4716 - dense_1_loss: 0.0560 - activation_8_loss: 0.4163-------------------------------------\n",
      "|      train_loss |           0.472 |\n",
      "|        val_loss |           0.199 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.4717 - dense_1_loss: 0.0560 - activation_8_loss: 0.4164 - val_loss: 0.1994 - val_dense_1_loss: 0.0722 - val_activation_8_loss: 0.1274\n",
      "1.0\n",
      "0.99863964\n",
      "Epoch 77/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4600-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.221 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4599 - val_loss: 0.2212 - val_dense_1_loss: 0.0677 - val_activation_8_loss: 0.1537\n",
      "1.0\n",
      "0.9987691\n",
      "Epoch 78/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5147 - dense_1_loss: 0.0560 - activation_8_loss: 0.4593-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |            0.23 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.5148 - dense_1_loss: 0.0560 - activation_8_loss: 0.4593 - val_loss: 0.2297 - val_dense_1_loss: 0.0693 - val_activation_8_loss: 0.1605\n",
      "1.0\n",
      "0.9988862\n",
      "Epoch 79/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4597-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.227 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4597 - val_loss: 0.2274 - val_dense_1_loss: 0.0686 - val_activation_8_loss: 0.1590\n",
      "1.0\n",
      "0.9989922\n",
      "Epoch 80/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5145 - dense_1_loss: 0.0560 - activation_8_loss: 0.4590-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.219 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.5146 - dense_1_loss: 0.0560 - activation_8_loss: 0.4591 - val_loss: 0.2194 - val_dense_1_loss: 0.0677 - val_activation_8_loss: 0.1519\n",
      "1.0\n",
      "0.9990881\n",
      "Epoch 81/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.222 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 663s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596 - val_loss: 0.2225 - val_dense_1_loss: 0.0714 - val_activation_8_loss: 0.1512\n",
      "1.0\n",
      "0.9991749\n",
      "Epoch 82/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |            0.23 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596 - val_loss: 0.2302 - val_dense_1_loss: 0.0692 - val_activation_8_loss: 0.1611\n",
      "1.0\n",
      "0.9992534\n",
      "Epoch 83/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5152 - dense_1_loss: 0.0559 - activation_8_loss: 0.4597-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.205 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 [==============================] - 662s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596 - val_loss: 0.2047 - val_dense_1_loss: 0.0661 - val_activation_8_loss: 0.1387\n",
      "1.0\n",
      "0.99932444\n",
      "Epoch 84/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5155 - dense_1_loss: 0.0560 - activation_8_loss: 0.4598-------------------------------------\n",
      "|      train_loss |           0.516 |\n",
      "|        val_loss |            0.22 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.5156 - dense_1_loss: 0.0560 - activation_8_loss: 0.4599 - val_loss: 0.2201 - val_dense_1_loss: 0.0700 - val_activation_8_loss: 0.1503\n",
      "1.0\n",
      "0.99938875\n",
      "Epoch 85/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5150 - dense_1_loss: 0.0560 - activation_8_loss: 0.4593-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.232 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.5151 - dense_1_loss: 0.0560 - activation_8_loss: 0.4594 - val_loss: 0.2320 - val_dense_1_loss: 0.0710 - val_activation_8_loss: 0.1611\n",
      "1.0\n",
      "0.9994469\n",
      "Epoch 86/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5156 - dense_1_loss: 0.0560 - activation_8_loss: 0.4598-------------------------------------\n",
      "|      train_loss |           0.516 |\n",
      "|        val_loss |           0.215 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5155 - dense_1_loss: 0.0560 - activation_8_loss: 0.4598 - val_loss: 0.2154 - val_dense_1_loss: 0.0638 - val_activation_8_loss: 0.1516\n",
      "1.0\n",
      "0.99949956\n",
      "Epoch 87/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5154 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.234 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.5154 - dense_1_loss: 0.0560 - activation_8_loss: 0.4596 - val_loss: 0.2335 - val_dense_1_loss: 0.0688 - val_activation_8_loss: 0.1648\n",
      "1.0\n",
      "0.9995472\n",
      "Epoch 88/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5149 - dense_1_loss: 0.0560 - activation_8_loss: 0.4591-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.212 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.5149 - dense_1_loss: 0.0560 - activation_8_loss: 0.4591 - val_loss: 0.2124 - val_dense_1_loss: 0.0692 - val_activation_8_loss: 0.1433\n",
      "1.0\n",
      "0.9995903\n",
      "Epoch 89/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5152 - dense_1_loss: 0.0560 - activation_8_loss: 0.4593-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.227 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5151 - dense_1_loss: 0.0560 - activation_8_loss: 0.4593 - val_loss: 0.2266 - val_dense_1_loss: 0.0711 - val_activation_8_loss: 0.1556\n",
      "1.0\n",
      "0.99962926\n",
      "Epoch 90/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4595-------------------------------------\n",
      "|      train_loss |           0.515 |\n",
      "|        val_loss |           0.221 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5153 - dense_1_loss: 0.0560 - activation_8_loss: 0.4595 - val_loss: 0.2206 - val_dense_1_loss: 0.0669 - val_activation_8_loss: 0.1538\n",
      "1.0\n",
      "0.99966455\n",
      "Epoch 91/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5155 - dense_1_loss: 0.0560 - activation_8_loss: 0.4597-------------------------------------\n",
      "|      train_loss |           0.516 |\n",
      "|        val_loss |           0.217 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.5155 - dense_1_loss: 0.0560 - activation_8_loss: 0.4597 - val_loss: 0.2173 - val_dense_1_loss: 0.0682 - val_activation_8_loss: 0.1492\n",
      "1.0\n",
      "0.99969643\n",
      "Epoch 92/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5644 - dense_1_loss: 0.0560 - activation_8_loss: 0.5086-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.257 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.5644 - dense_1_loss: 0.0560 - activation_8_loss: 0.5086 - val_loss: 0.2569 - val_dense_1_loss: 0.0721 - val_activation_8_loss: 0.1849\n",
      "1.0\n",
      "0.99972534\n",
      "Epoch 93/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5640 - dense_1_loss: 0.0560 - activation_8_loss: 0.5081-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.262 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.5640 - dense_1_loss: 0.0560 - activation_8_loss: 0.5081 - val_loss: 0.2616 - val_dense_1_loss: 0.0691 - val_activation_8_loss: 0.1925\n",
      "1.0\n",
      "0.9997515\n",
      "Epoch 94/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5642 - dense_1_loss: 0.0560 - activation_8_loss: 0.5083-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.268 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5642 - dense_1_loss: 0.0560 - activation_8_loss: 0.5084 - val_loss: 0.2685 - val_dense_1_loss: 0.0670 - val_activation_8_loss: 0.2016\n",
      "1.0\n",
      "0.9997751\n",
      "Epoch 95/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5634 - dense_1_loss: 0.0560 - activation_8_loss: 0.5075-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.248 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.5635 - dense_1_loss: 0.0560 - activation_8_loss: 0.5076 - val_loss: 0.2481 - val_dense_1_loss: 0.0684 - val_activation_8_loss: 0.1797\n",
      "1.0\n",
      "0.9997965\n",
      "Epoch 96/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5634 - dense_1_loss: 0.0560 - activation_8_loss: 0.5075-------------------------------------\n",
      "|      train_loss |           0.563 |\n",
      "|        val_loss |           0.269 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.5635 - dense_1_loss: 0.0560 - activation_8_loss: 0.5076 - val_loss: 0.2692 - val_dense_1_loss: 0.0700 - val_activation_8_loss: 0.1993\n",
      "1.0\n",
      "0.9998159\n",
      "Epoch 97/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5646 - dense_1_loss: 0.0560 - activation_8_loss: 0.5087-------------------------------------\n",
      "|      train_loss |           0.565 |\n",
      "|        val_loss |           0.249 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.5645 - dense_1_loss: 0.0560 - activation_8_loss: 0.5087 - val_loss: 0.2493 - val_dense_1_loss: 0.0690 - val_activation_8_loss: 0.1803\n",
      "1.0\n",
      "0.9998334\n",
      "Epoch 98/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5636 - dense_1_loss: 0.0560 - activation_8_loss: 0.5077-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.253 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 663s - loss: 0.5636 - dense_1_loss: 0.0560 - activation_8_loss: 0.5077 - val_loss: 0.2535 - val_dense_1_loss: 0.0682 - val_activation_8_loss: 0.1853\n",
      "1.0\n",
      "0.99984926\n",
      "Epoch 99/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5638 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.265 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.5638 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079 - val_loss: 0.2651 - val_dense_1_loss: 0.0684 - val_activation_8_loss: 0.1967\n",
      "1.0\n",
      "0.9998636\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5641 - dense_1_loss: 0.0559 - activation_8_loss: 0.5083-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.255 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_99.h5\n",
      "3856/3856 [==============================] - 653s - loss: 0.5641 - dense_1_loss: 0.0560 - activation_8_loss: 0.5082 - val_loss: 0.2549 - val_dense_1_loss: 0.0701 - val_activation_8_loss: 0.1847\n",
      "1.0\n",
      "0.9998766\n",
      "Epoch 101/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5640 - dense_1_loss: 0.0560 - activation_8_loss: 0.5081-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.265 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.5640 - dense_1_loss: 0.0560 - activation_8_loss: 0.5081 - val_loss: 0.2645 - val_dense_1_loss: 0.0686 - val_activation_8_loss: 0.1959\n",
      "1.0\n",
      "0.99988836\n",
      "Epoch 102/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5631 - dense_1_loss: 0.0560 - activation_8_loss: 0.5072-------------------------------------\n",
      "|      train_loss |           0.563 |\n",
      "|        val_loss |           0.261 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 652s - loss: 0.5632 - dense_1_loss: 0.0560 - activation_8_loss: 0.5072 - val_loss: 0.2613 - val_dense_1_loss: 0.0712 - val_activation_8_loss: 0.1901\n",
      "1.0\n",
      "0.99989897\n",
      "Epoch 103/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5639 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.258 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.5638 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079 - val_loss: 0.2578 - val_dense_1_loss: 0.0690 - val_activation_8_loss: 0.1888\n",
      "1.0\n",
      "0.99990857\n",
      "Epoch 104/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5639 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.258 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.5638 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079 - val_loss: 0.2580 - val_dense_1_loss: 0.0703 - val_activation_8_loss: 0.1878\n",
      "1.0\n",
      "0.99991727\n",
      "Epoch 105/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5639 - dense_1_loss: 0.0560 - activation_8_loss: 0.5080-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.265 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 655s - loss: 0.5639 - dense_1_loss: 0.0560 - activation_8_loss: 0.5079 - val_loss: 0.2653 - val_dense_1_loss: 0.0689 - val_activation_8_loss: 0.1965\n",
      "1.0\n",
      "0.99992514\n",
      "Epoch 106/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5642 - dense_1_loss: 0.0560 - activation_8_loss: 0.5083-------------------------------------\n",
      "|      train_loss |           0.564 |\n",
      "|        val_loss |           0.256 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.5642 - dense_1_loss: 0.0560 - activation_8_loss: 0.5083 - val_loss: 0.2558 - val_dense_1_loss: 0.0715 - val_activation_8_loss: 0.1843\n",
      "1.0\n",
      "0.9999323\n",
      "Epoch 107/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5697 - dense_1_loss: 0.0616 - activation_8_loss: 0.5081-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.254 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082 - val_loss: 0.2545 - val_dense_1_loss: 0.0727 - val_activation_8_loss: 0.1818\n",
      "1.0\n",
      "0.9999387\n",
      "Epoch 108/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.261 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082 - val_loss: 0.2612 - val_dense_1_loss: 0.0758 - val_activation_8_loss: 0.1853\n",
      "1.0\n",
      "0.99994457\n",
      "Epoch 109/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.283 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 656s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078 - val_loss: 0.2827 - val_dense_1_loss: 0.0760 - val_activation_8_loss: 0.2067\n",
      "1.0\n",
      "0.9999498\n",
      "Epoch 110/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5696 - dense_1_loss: 0.0616 - activation_8_loss: 0.5080-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.256 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.5695 - dense_1_loss: 0.0616 - activation_8_loss: 0.5079 - val_loss: 0.2562 - val_dense_1_loss: 0.0760 - val_activation_8_loss: 0.1802\n",
      "1.0\n",
      "0.9999546\n",
      "Epoch 111/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.261 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 658s - loss: 0.5699 - dense_1_loss: 0.0616 - activation_8_loss: 0.5083 - val_loss: 0.2609 - val_dense_1_loss: 0.0761 - val_activation_8_loss: 0.1849\n",
      "1.0\n",
      "0.99995893\n",
      "Epoch 112/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.277 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 659s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078 - val_loss: 0.2769 - val_dense_1_loss: 0.0753 - val_activation_8_loss: 0.2016\n",
      "1.0\n",
      "0.9999628\n",
      "Epoch 113/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5695 - dense_1_loss: 0.0616 - activation_8_loss: 0.5079-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.262 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 660s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078 - val_loss: 0.2620 - val_dense_1_loss: 0.0748 - val_activation_8_loss: 0.1872\n",
      "1.0\n",
      "0.9999664\n",
      "Epoch 114/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5697 - dense_1_loss: 0.0616 - activation_8_loss: 0.5081-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.264 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 662s - loss: 0.5697 - dense_1_loss: 0.0616 - activation_8_loss: 0.5081 - val_loss: 0.2644 - val_dense_1_loss: 0.0775 - val_activation_8_loss: 0.1869\n",
      "1.0\n",
      "0.99996954\n",
      "Epoch 115/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5699 - dense_1_loss: 0.0616 - activation_8_loss: 0.5083-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.269 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 661s - loss: 0.5699 - dense_1_loss: 0.0616 - activation_8_loss: 0.5084 - val_loss: 0.2686 - val_dense_1_loss: 0.0749 - val_activation_8_loss: 0.1937\n",
      "1.0\n",
      "0.99997246\n",
      "Epoch 116/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5694 - dense_1_loss: 0.0616 - activation_8_loss: 0.5078-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.259 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 [==============================] - 664s - loss: 0.5695 - dense_1_loss: 0.0616 - activation_8_loss: 0.5079 - val_loss: 0.2595 - val_dense_1_loss: 0.0771 - val_activation_8_loss: 0.1824\n",
      "1.0\n",
      "0.9999751\n",
      "Epoch 117/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.273 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 649s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082 - val_loss: 0.2730 - val_dense_1_loss: 0.0752 - val_activation_8_loss: 0.1979\n",
      "1.0\n",
      "0.99997747\n",
      "Epoch 118/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.259 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 667s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082 - val_loss: 0.2595 - val_dense_1_loss: 0.0756 - val_activation_8_loss: 0.1839\n",
      "1.0\n",
      "0.9999796\n",
      "Epoch 119/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5702 - dense_1_loss: 0.0616 - activation_8_loss: 0.5086-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.267 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 665s - loss: 0.5701 - dense_1_loss: 0.0616 - activation_8_loss: 0.5085 - val_loss: 0.2667 - val_dense_1_loss: 0.0786 - val_activation_8_loss: 0.1881\n",
      "1.0\n",
      "0.9999815\n",
      "Epoch 120/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5696 - dense_1_loss: 0.0616 - activation_8_loss: 0.5080-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.267 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 667s - loss: 0.5696 - dense_1_loss: 0.0616 - activation_8_loss: 0.5080 - val_loss: 0.2666 - val_dense_1_loss: 0.0755 - val_activation_8_loss: 0.1911\n",
      "1.0\n",
      "0.9999833\n",
      "Epoch 121/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5698 - dense_1_loss: 0.0615 - activation_8_loss: 0.5082-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.257 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 666s - loss: 0.5698 - dense_1_loss: 0.0616 - activation_8_loss: 0.5082 - val_loss: 0.2573 - val_dense_1_loss: 0.0728 - val_activation_8_loss: 0.1845\n",
      "1.0\n",
      "0.99998486\n",
      "Epoch 122/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5693 - dense_1_loss: 0.0616 - activation_8_loss: 0.5077-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.264 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 667s - loss: 0.5692 - dense_1_loss: 0.0616 - activation_8_loss: 0.5076 - val_loss: 0.2642 - val_dense_1_loss: 0.0768 - val_activation_8_loss: 0.1874\n",
      "1.0\n",
      "0.99998635\n",
      "Epoch 123/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5693 - dense_1_loss: 0.0616 - activation_8_loss: 0.5077-------------------------------------\n",
      "|      train_loss |           0.569 |\n",
      "|        val_loss |           0.268 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 668s - loss: 0.5693 - dense_1_loss: 0.0616 - activation_8_loss: 0.5077 - val_loss: 0.2679 - val_dense_1_loss: 0.0761 - val_activation_8_loss: 0.1919\n",
      "1.0\n",
      "0.9999876\n",
      "Epoch 124/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.5703 - dense_1_loss: 0.0616 - activation_8_loss: 0.5087-------------------------------------\n",
      "|      train_loss |            0.57 |\n",
      "|        val_loss |           0.275 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 664s - loss: 0.5702 - dense_1_loss: 0.0616 - activation_8_loss: 0.5086 - val_loss: 0.2745 - val_dense_1_loss: 0.0751 - val_activation_8_loss: 0.1994\n",
      "1.0\n",
      "0.9999888\n",
      "Epoch 125/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.325 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_124.h5\n",
      "3856/3856 [==============================] - 670s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624 - val_loss: 0.3249 - val_dense_1_loss: 0.0761 - val_activation_8_loss: 0.2488\n",
      "1.0\n",
      "0.99998987\n",
      "Epoch 126/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6234 - dense_1_loss: 0.0616 - activation_8_loss: 0.5618-------------------------------------\n",
      "|      train_loss |           0.623 |\n",
      "|        val_loss |           0.314 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 670s - loss: 0.6235 - dense_1_loss: 0.0616 - activation_8_loss: 0.5619 - val_loss: 0.3136 - val_dense_1_loss: 0.0778 - val_activation_8_loss: 0.2359\n",
      "1.0\n",
      "0.9999908\n",
      "Epoch 127/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6238 - dense_1_loss: 0.0616 - activation_8_loss: 0.5622-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.317 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 670s - loss: 0.6238 - dense_1_loss: 0.0616 - activation_8_loss: 0.5622 - val_loss: 0.3171 - val_dense_1_loss: 0.0772 - val_activation_8_loss: 0.2399\n",
      "1.0\n",
      "0.9999917\n",
      "Epoch 128/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.328 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 672s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624 - val_loss: 0.3276 - val_dense_1_loss: 0.0742 - val_activation_8_loss: 0.2535\n",
      "1.0\n",
      "0.9999925\n",
      "Epoch 129/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6243 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.319 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 672s - loss: 0.6243 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627 - val_loss: 0.3193 - val_dense_1_loss: 0.0758 - val_activation_8_loss: 0.2435\n",
      "1.0\n",
      "0.9999932\n",
      "Epoch 130/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6235 - dense_1_loss: 0.0616 - activation_8_loss: 0.5619-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |            0.32 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 673s - loss: 0.6236 - dense_1_loss: 0.0616 - activation_8_loss: 0.5620 - val_loss: 0.3201 - val_dense_1_loss: 0.0763 - val_activation_8_loss: 0.2438\n",
      "1.0\n",
      "0.99999386\n",
      "Epoch 131/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5626-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.309 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 669s - loss: 0.6241 - dense_1_loss: 0.0616 - activation_8_loss: 0.5625 - val_loss: 0.3090 - val_dense_1_loss: 0.0757 - val_activation_8_loss: 0.2333\n",
      "1.0\n",
      "0.99999446\n",
      "Epoch 132/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6237 - dense_1_loss: 0.0615 - activation_8_loss: 0.5621-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.313 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 674s - loss: 0.6237 - dense_1_loss: 0.0616 - activation_8_loss: 0.5621 - val_loss: 0.3125 - val_dense_1_loss: 0.0745 - val_activation_8_loss: 0.2380\n",
      "1.0\n",
      "0.999995\n",
      "Epoch 133/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6244 - dense_1_loss: 0.0616 - activation_8_loss: 0.5628-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.318 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.6244 - dense_1_loss: 0.0616 - activation_8_loss: 0.5628 - val_loss: 0.3175 - val_dense_1_loss: 0.0753 - val_activation_8_loss: 0.2422\n",
      "1.0\n",
      "0.99999547\n",
      "Epoch 134/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6235 - dense_1_loss: 0.0616 - activation_8_loss: 0.5619-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.327 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 651s - loss: 0.6236 - dense_1_loss: 0.0616 - activation_8_loss: 0.5620 - val_loss: 0.3274 - val_dense_1_loss: 0.0771 - val_activation_8_loss: 0.2503\n",
      "1.0\n",
      "0.9999959\n",
      "Epoch 135/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5626-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.319 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 654s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5626 - val_loss: 0.3192 - val_dense_1_loss: 0.0766 - val_activation_8_loss: 0.2425\n",
      "1.0\n",
      "0.99999624\n",
      "Epoch 136/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6241 - dense_1_loss: 0.0616 - activation_8_loss: 0.5625-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.316 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 653s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5626 - val_loss: 0.3155 - val_dense_1_loss: 0.0755 - val_activation_8_loss: 0.2400\n",
      "1.0\n",
      "0.9999966\n",
      "Epoch 137/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6234 - dense_1_loss: 0.0616 - activation_8_loss: 0.5618-------------------------------------\n",
      "|      train_loss |           0.623 |\n",
      "|        val_loss |           0.322 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 667s - loss: 0.6234 - dense_1_loss: 0.0616 - activation_8_loss: 0.5618 - val_loss: 0.3216 - val_dense_1_loss: 0.0746 - val_activation_8_loss: 0.2471\n",
      "1.0\n",
      "0.99999696\n",
      "Epoch 138/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6238 - dense_1_loss: 0.0616 - activation_8_loss: 0.5623-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.318 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 669s - loss: 0.6239 - dense_1_loss: 0.0616 - activation_8_loss: 0.5623 - val_loss: 0.3184 - val_dense_1_loss: 0.0750 - val_activation_8_loss: 0.2434\n",
      "1.0\n",
      "0.99999726\n",
      "Epoch 139/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6237 - dense_1_loss: 0.0615 - activation_8_loss: 0.5621-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.319 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 669s - loss: 0.6237 - dense_1_loss: 0.0616 - activation_8_loss: 0.5621 - val_loss: 0.3194 - val_dense_1_loss: 0.0761 - val_activation_8_loss: 0.2433\n",
      "1.0\n",
      "0.9999975\n",
      "Epoch 140/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6241 - dense_1_loss: 0.0616 - activation_8_loss: 0.5625-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.317 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 669s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624 - val_loss: 0.3168 - val_dense_1_loss: 0.0766 - val_activation_8_loss: 0.2403\n",
      "1.0\n",
      "0.99999774\n",
      "Epoch 141/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6237 - dense_1_loss: 0.0616 - activation_8_loss: 0.5622-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.319 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 670s - loss: 0.6239 - dense_1_loss: 0.0616 - activation_8_loss: 0.5623 - val_loss: 0.3189 - val_dense_1_loss: 0.0745 - val_activation_8_loss: 0.2444\n",
      "1.0\n",
      "0.999998\n",
      "Epoch 142/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |            0.33 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 670s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627 - val_loss: 0.3296 - val_dense_1_loss: 0.0780 - val_activation_8_loss: 0.2516\n",
      "1.0\n",
      "0.99999815\n",
      "Epoch 143/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6236 - dense_1_loss: 0.0616 - activation_8_loss: 0.5621-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.314 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 674s - loss: 0.6236 - dense_1_loss: 0.0616 - activation_8_loss: 0.5620 - val_loss: 0.3145 - val_dense_1_loss: 0.0780 - val_activation_8_loss: 0.2364\n",
      "1.0\n",
      "0.99999833\n",
      "Epoch 144/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6243 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.309 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 671s - loss: 0.6242 - dense_1_loss: 0.0616 - activation_8_loss: 0.5627 - val_loss: 0.3093 - val_dense_1_loss: 0.0730 - val_activation_8_loss: 0.2363\n",
      "1.0\n",
      "0.9999985\n",
      "Epoch 145/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6234 - dense_1_loss: 0.0616 - activation_8_loss: 0.5618-------------------------------------\n",
      "|      train_loss |           0.623 |\n",
      "|        val_loss |           0.328 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 672s - loss: 0.6233 - dense_1_loss: 0.0616 - activation_8_loss: 0.5617 - val_loss: 0.3277 - val_dense_1_loss: 0.0770 - val_activation_8_loss: 0.2507\n",
      "1.0\n",
      "0.9999986\n",
      "Epoch 146/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6245 - dense_1_loss: 0.0616 - activation_8_loss: 0.5629-------------------------------------\n",
      "|      train_loss |           0.625 |\n",
      "|        val_loss |           0.317 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 673s - loss: 0.6245 - dense_1_loss: 0.0616 - activation_8_loss: 0.5629 - val_loss: 0.3170 - val_dense_1_loss: 0.0771 - val_activation_8_loss: 0.2399\n",
      "1.0\n",
      "0.99999875\n",
      "Epoch 147/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6232 - dense_1_loss: 0.0616 - activation_8_loss: 0.5616-------------------------------------\n",
      "|      train_loss |           0.623 |\n",
      "|        val_loss |           0.328 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 671s - loss: 0.6232 - dense_1_loss: 0.0616 - activation_8_loss: 0.5616 - val_loss: 0.3277 - val_dense_1_loss: 0.0754 - val_activation_8_loss: 0.2524\n",
      "1.0\n",
      "0.99999887\n",
      "Epoch 148/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6239 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.314 |\n",
      "-------------------------------------\n",
      "3856/3856 [==============================] - 671s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624 - val_loss: 0.3141 - val_dense_1_loss: 0.0753 - val_activation_8_loss: 0.2388\n",
      "1.0\n",
      "0.999999\n",
      "Epoch 149/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6241 - dense_1_loss: 0.0616 - activation_8_loss: 0.5625-------------------------------------\n",
      "|      train_loss |           0.624 |\n",
      "|        val_loss |           0.326 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 [==============================] - 675s - loss: 0.6240 - dense_1_loss: 0.0616 - activation_8_loss: 0.5624 - val_loss: 0.3264 - val_dense_1_loss: 0.0772 - val_activation_8_loss: 0.2492\n",
      "1.0\n",
      "0.9999991\n",
      "Epoch 150/150\n",
      "3855/3856 [============================>.] - ETA: 0s - loss: 0.6233 - dense_1_loss: 0.0616 - activation_8_loss: 0.5617-------------------------------------\n",
      "|      train_loss |           0.623 |\n",
      "|        val_loss |           0.318 |\n",
      "-------------------------------------\n",
      "Saved model at ./model/test_1/model_weights_149.h5\n",
      "3856/3856 [==============================] - 649s - loss: 0.6232 - dense_1_loss: 0.0616 - activation_8_loss: 0.5616 - val_loss: 0.3181 - val_dense_1_loss: 0.0774 - val_activation_8_loss: 0.2407\n"
     ]
    }
   ],
   "source": [
    "%run cnn.py --experiment_rootdir='./model/test_1' --train_dir='./data/training' --val_dir='./data/validation' --batch_size=16 --epochs=150 --log_rate=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6855 images belonging to 9 experiments.\n",
      "Loaded model from ./model/test_1/model_weights_149.h5\n",
      "429/429 [==============================] - 70s    \n",
      "EVA = 0.0\n",
      "RMSE = 0.21290822327136993\n",
      "Written file ./model/test_1/constant_regression.json\n",
      "EVA = 0.0\n",
      "RMSE = 0.21460199356079102\n",
      "Written file ./model/test_1/test_regression.json\n",
      "EVA = -1.0482769993956822\n",
      "RMSE = 0.30472281730667894\n",
      "Written file ./model/test_1/random_regression.json\n",
      "Written file ./model/test_1/predicted_and_real_steerings.json\n",
      "Average accuracy =  0.5145939086294417\n",
      "Precision =  0.22086720867208673\n",
      "Recall =  0.22086720867208673\n",
      "F1-score =  0.29880843263061413\n",
      "Written file ./model/test_1/random_classification.json\n",
      "Average accuracy =  0.7760152284263959\n",
      "Precision =  0.0\n",
      "Recall =  0.0\n",
      "F1-score =  0.0\n",
      "Written file ./model/test_1/test_classification.json\n",
      "Written file ./model/test_1/predicted_and_real_labels.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/miniconda3/envs/rpg_public_dronet/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/joe/miniconda3/envs/rpg_public_dronet/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%run evaluation.py --experiment_rootdir='./model/test_1' --weights_fname='model_weights_149.h5' --test_dir='./data/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
